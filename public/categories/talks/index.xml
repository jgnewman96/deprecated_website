<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Talks on Welcome</title>
    <link>https://judahgnewman.netlify.com/categories/talks/</link>
    <description>Recent content in Talks on Welcome</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 02 Nov 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://judahgnewman.netlify.com/categories/talks/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ODSC</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/odsc/</link>
      <pubDate>Sat, 02 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/odsc/</guid>
      <description>I attended ODSC (Open Data Science Conference) West in October 2019. Here are the notes that I took from every session that I attended while I was there.
Day 1, Tuesday October 29, 2019 Interpretable Knowledge Discovery Reinforced by Visual Methods
User-Centric Design for Data Scientists
ML Flow: Platform for Complete Machine Learning Life Cycle
Day 2, Wednesday October 30, 2019 Implict Deep Learning
Towards a Blend of Machine Learning and Microeconomics</description>
    </item>
    
    <item>
      <title>Declarative Data Visualization with Vega-Lite and Altair</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/vega_altair_odsc/</link>
      <pubDate>Thu, 31 Oct 2019 15:51:05 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/vega_altair_odsc/</guid>
      <description>Talk given by Dominik Moritz at Apple/CMU and Kanit &amp;ldquo;Ham&amp;rdquo; Wongsuphasawat at Apple
Motivation So what is declarative data visualization? As programmers we are used to imperative programming. Imperative programming is specifying how to do a problem. For example you say, put a red circle here and put a blue circle there. It couples the specification with the execution. In declarative programming we only specify what should be done. We would say map x and y to specific position, not how to max x and y.</description>
    </item>
    
    <item>
      <title>Trouble shooting Deep Neural Networks</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/troubleshoot_nn_odsc/</link>
      <pubDate>Thu, 31 Oct 2019 11:51:11 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/troubleshoot_nn_odsc/</guid>
      <description>Talk given by Josh Tobin works at Open Ai and Full stack Deep Learning. Talk Resources
Motivation Troubleshooting neurel nets is hardest part of building a deep model. Even the best practitioners spend a long time trouble shooting. Josh argues that the vast majority of what the best practitioners do to troubleshoot their models can be broken down to a decision tree. During this talk he presents that decision tree.</description>
    </item>
    
    <item>
      <title>AI Neuroscience: Can we understand the neural networks we train?</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/uber_ai_neuroscience_odsc/</link>
      <pubDate>Thu, 31 Oct 2019 10:55:26 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/uber_ai_neuroscience_odsc/</guid>
      <description>Talk given by Jason Yosinski. He works at Uber AI Labs and Recursion Pharmaceuticals
Motivation We train and use neural netwroks but we have a very minimal grasp on how they actual work. We have created systems that can beat humans players in games and actually create robots that can work. We have made huge advances in creating systems that can do impressive things. Most of the this improve has been driven by increase in computation and increase in amounts of data.</description>
    </item>
    
    <item>
      <title>ODSC Keynotes</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/keynotes_odsc/</link>
      <pubDate>Thu, 31 Oct 2019 08:22:50 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/keynotes_odsc/</guid>
      <description>AI Lifecycle Model Management: Monitoring for Risk, Bias and Fairness Talk given by Sepideh Seifzadeh
The first keynote was about how can we as data scientists monitor for risk, bias and fairness. The speaker motivated the tech by saying that AI and data regulation is coming. There is more data being collected, Machine Learning capabilities have increased and the cost of storage is now a lot lower.
The speaker highlighted how we do not have defined mechanisms in place to handle when their are problems with AI.</description>
    </item>
    
    <item>
      <title>Welcoming Remarks</title>
      <link>https://judahgnewman.netlify.com/writing/talks/cade_workshop/</link>
      <pubDate>Thu, 31 Oct 2019 08:02:37 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/cade_workshop/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Tackling Climate Change with Machine Learning</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/climate_change_odsc/</link>
      <pubDate>Wed, 30 Oct 2019 15:58:02 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/climate_change_odsc/</guid>
      <description>Talk given by David Rolnick University of Pennsylvania and founder of Climate Change AI
Motivation Climate change as an important issues does not need that much motivation. We have all seen what has been happening California recently with the wild fires. There has been increasingly severe impacts from human influence on our climate system.
One thing that is important to recognize about climate change is that different parts of the world are impacted differently.</description>
    </item>
    
    <item>
      <title>Principled Methods for Analyzing Weight Matrices of Modern Production Quality Neural Networks</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/inspecting_deep_learning_odsc/</link>
      <pubDate>Wed, 30 Oct 2019 13:55:58 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/inspecting_deep_learning_odsc/</guid>
      <description>Talk given by Michael Mahoney and Charles H. Martin
Talk Slides
Github
Motivation What most practitioners of deep learning do is train models. Training models that do something is the easy part. The hard part is actually evaluating and testing those models. Most people evaluate their models by tieing them to a certain set of data and seeing the accuracy on that data. This has problem because it is tied to a given set of data and the potential problems with that data.</description>
    </item>
    
    <item>
      <title>Building Intelligent Agents That Can Interpret, Generate and Learn from Natural Language</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/agents_language_odsc/</link>
      <pubDate>Wed, 30 Oct 2019 10:50:20 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/agents_language_odsc/</guid>
      <description>Talk given by Jacob Andreas
Motivation Ideally we have systems that understand us in our natural language and can do things. We are beginning to have autonomous agents in the world around us. Both agents in the virtual world such a personal assistants and agents in the physical world like Roombas. We want to build automated agents that can take actions based on natural language
How do we design agents?</description>
    </item>
    
    <item>
      <title>Towards a Blend of Machine Learning and Microeconomics</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/ml_microecon/</link>
      <pubDate>Wed, 30 Oct 2019 09:51:58 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/ml_microecon/</guid>
      <description>Talk given by Michael I Jordan
What is Machine Learning? The talk started by Professor Jordan defining what Machine Learning is. He said that machine learning is not some new field of research but it is rather the engineering extension of statistics. He calls back to how there was chemistry for a long time before there was chemical engineering. There was physics and electrical theory before there was electrical engineering.</description>
    </item>
    
    <item>
      <title>Implict Deep Learning </title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/implicit_learning_odsc/</link>
      <pubDate>Wed, 30 Oct 2019 08:33:02 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/implicit_learning_odsc/</guid>
      <description>Talk given by Laurent El Ghaoui : Professor at BAIR and chief scientist at Sumup Analytics
This talk was about a new area of Deep Learning research that is still very much theory. In this approach rather than specifying the architecture of a given model, the data tells us the structure of our model. This approach provides for new notation and new conceptual ways for us to think about deep learning.</description>
    </item>
    
    <item>
      <title>ML Flow: Platform for Complete Machine Learning Life Cycle</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/mlflow_odsc/</link>
      <pubDate>Tue, 29 Oct 2019 13:53:00 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/mlflow_odsc/</guid>
      <description>Talk given by Jules Damji: git hub repo
Motivation Machine learning development is complex. This is not due to the underlying theory but rather all of the different stages in development. Each stage has its own requirements and goals. We have developed tools and best practices for this for traditional software development, but not Machine Learning.
Here are the differences between traditional software and machine learning
Traditional Software:
 Meet a functional specification Quality depends on the code One software stack  Machine Learning</description>
    </item>
    
    <item>
      <title>User-Centric Design for Data Scientists</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/user_centeric_design_odsc/</link>
      <pubDate>Tue, 29 Oct 2019 11:47:50 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/user_centeric_design_odsc/</guid>
      <description>By Annie Darmofal and Katie Malone
They both work at Tempus
Motivation Even if we build the most incredible thing, if it is not designed with users in mind, no body will use it. If we have built something that nobody will use, is it even incredible. If nobody is using what we have built than that is a failing.
We can build tools that users actually care about and will use if we take a user-centered design approach.</description>
    </item>
    
    <item>
      <title>Interpretable Knowledge Discovery Reinforced by Visual Methods</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/kdd_odsc/</link>
      <pubDate>Tue, 29 Oct 2019 08:05:34 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/kdd_odsc/</guid>
      <description>Talk given by Boris Kovalerchuk , Slides
Motivation Boris motivated the need for visual techniques with an example on the Iris data set. He showed three different models for the Iris data set, shown below.
He highlighted that the problem with each of these analytical approaches is that they generalize to areas we have seen before. Ideally, instead we would have a model that classified points in space we had seen before and refused to classify points in the unknown space.</description>
    </item>
    
  </channel>
</rss>