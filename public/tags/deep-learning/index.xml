<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on Welcome</title>
    <link>https://judahgnewman.netlify.com/tags/deep-learning/</link>
    <description>Recent content in Deep Learning on Welcome</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Sep 2020 16:02:40 -0700</lastBuildDate><atom:link href="https://judahgnewman.netlify.com/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Towards Fine-grained Flow Forecasting: A Graph Attention Approach for Bike Sharing Systems</title>
      <link>https://judahgnewman.netlify.com/writing/papers/2020/bike_share_forecasting/</link>
      <pubDate>Thu, 24 Sep 2020 16:02:40 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/papers/2020/bike_share_forecasting/</guid>
      <description>By Suining He and Kang Shin
Paper Motivation Accurate bike-flow prediction at the station level is important for a bike sharing service&amp;rsquo;s success. Existing methods are not successful at predicting fine-grained bike flow.
Paper Contribution The authors remedy this problem by proposing a spatiotemporal graph attention CNN for station-level flow prediction. Each bike station is a node and bike rides are edges on a graph. Their network captures differing station-to-station correlations.</description>
    </item>
    
    <item>
      <title>Understanding Deep Learning Requires Re-thinking Generalization</title>
      <link>https://judahgnewman.netlify.com/writing/papers/2020/rethinking_generalization/</link>
      <pubDate>Thu, 13 Aug 2020 17:39:34 -0400</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/papers/2020/rethinking_generalization/</guid>
      <description>By Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals
Papers Motivation The authors note that successful deep learning models often exhibit small differences between training and test performance. This is generally attributed to modeling techniques that are supposed to achieve generalization, such as regularization.
Papers Contribution Using many experiments, the authors show that these traditional approaches do not provide a satisfactory answers for why deep learning generalizes well. Regularization is not what leads to good generalization, and state of the art deep learning can successfully fit random noise.</description>
    </item>
    
    <item>
      <title>Generative Models for Effective Machine Learning On Private, Decentralized Datasets</title>
      <link>https://judahgnewman.netlify.com/writing/papers/2020/generative_models_privacy/</link>
      <pubDate>Sun, 02 Aug 2020 11:37:47 -0400</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/papers/2020/generative_models_privacy/</guid>
      <description>Paper by Augenstein et al.
I have stared a weekly reading group with my friend and former co-worker Tushar Chandra. Our format is that one person proposes a set of papers, and then the other picks a paper for the week.
Summary The authors motivate their paper with the following logical steps.
 Manual data inspection is a key part of the machine learning workflow There are occasions when manual data inspection is either undesirable or infeasible (privacy requirements, or federated learning where data is stored at the edge).</description>
    </item>
    
    <item>
      <title>Trouble shooting Deep Neural Networks</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/troubleshoot_nn_odsc/</link>
      <pubDate>Thu, 31 Oct 2019 11:51:11 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/troubleshoot_nn_odsc/</guid>
      <description>Talk given by Josh Tobin works at Open Ai and Full stack Deep Learning. Talk Resources
Motivation Troubleshooting neurel nets is hardest part of building a deep model. Even the best practitioners spend a long time trouble shooting. Josh argues that the vast majority of what the best practitioners do to troubleshoot their models can be broken down to a decision tree. During this talk he presents that decision tree. Generally, 80-90% of our time goes into debugging and tuning while only 10-20 percent is deriving math or building implemnations.</description>
    </item>
    
    <item>
      <title>AI Neuroscience: Can we understand the neural networks we train?</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/uber_ai_neuroscience_odsc/</link>
      <pubDate>Thu, 31 Oct 2019 10:55:26 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/uber_ai_neuroscience_odsc/</guid>
      <description>Talk given by Jason Yosinski. He works at Uber AI Labs and Recursion Pharmaceuticals
Motivation We train and use neural netwroks but we have a very minimal grasp on how they actual work. We have created systems that can beat humans players in games and actually create robots that can work. We have made huge advances in creating systems that can do impressive things. Most of the this improve has been driven by increase in computation and increase in amounts of data.</description>
    </item>
    
    <item>
      <title>Principled Methods for Analyzing Weight Matrices of Modern Production Quality Neural Networks</title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/inspecting_deep_learning_odsc/</link>
      <pubDate>Wed, 30 Oct 2019 13:55:58 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/inspecting_deep_learning_odsc/</guid>
      <description>Talk given by Michael Mahoney and Charles H. Martin
Talk Slides
Github
Motivation What most practitioners of deep learning do is train models. Training models that do something is the easy part. The hard part is actually evaluating and testing those models. Most people evaluate their models by tieing them to a certain set of data and seeing the accuracy on that data. This has problem because it is tied to a given set of data and the potential problems with that data.</description>
    </item>
    
    <item>
      <title>Implict Deep Learning </title>
      <link>https://judahgnewman.netlify.com/writing/talks/odsc/implicit_learning_odsc/</link>
      <pubDate>Wed, 30 Oct 2019 08:33:02 -0700</pubDate>
      
      <guid>https://judahgnewman.netlify.com/writing/talks/odsc/implicit_learning_odsc/</guid>
      <description>Talk given by Laurent El Ghaoui : Professor at BAIR and chief scientist at Sumup Analytics
This talk was about a new area of Deep Learning research that is still very much theory. In this approach rather than specifying the architecture of a given model, the data tells us the structure of our model. This approach provides for new notation and new conceptual ways for us to think about deep learning.</description>
    </item>
    
  </channel>
</rss>
